{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM and RF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9NKaBUl4pB39",
        "o0xNNbvyS_Wu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEdKOdFOiasy"
      },
      "source": [
        "# Data Retrieval \r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nbMHsdVgIU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc489e1-d3df-4615-cf4c-b397e356c8b8"
      },
      "source": [
        " from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        " "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0EW1FZ-g2s-"
      },
      "source": [
        "import pandas as pd\r\n",
        "# read functional data (atlas)\r\n",
        "func_aal = pd.read_csv(\"drive/MyDrive/func_aal.csv\") \r\n",
        "# read structural data (standard scaling)\r\n",
        "str_sc_std = pd.read_csv(\"drive/MyDrive/struct_scaled.csv\")\r\n",
        "# read structural data (raw)\r\n",
        "str_unsc = pd.read_csv(\"drive/MyDrive/struct_unscaled.csv\")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b8Iv8TDDiVmI",
        "outputId": "7cc4fd5a-8b3e-4006-b071-9897b2fd6905"
      },
      "source": [
        "str_sc_std.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>486</th>\n",
              "      <th>487</th>\n",
              "      <th>488</th>\n",
              "      <th>489</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "      <th>501</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>520</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "      <th>Class</th>\n",
              "      <th>subject_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.562779</td>\n",
              "      <td>-0.485444</td>\n",
              "      <td>-0.022433</td>\n",
              "      <td>-0.507401</td>\n",
              "      <td>-0.251055</td>\n",
              "      <td>-0.304714</td>\n",
              "      <td>-0.803646</td>\n",
              "      <td>0.635777</td>\n",
              "      <td>-1.665046</td>\n",
              "      <td>-0.252324</td>\n",
              "      <td>-0.333041</td>\n",
              "      <td>0.150130</td>\n",
              "      <td>-1.453433</td>\n",
              "      <td>-0.877611</td>\n",
              "      <td>0.366583</td>\n",
              "      <td>-0.577094</td>\n",
              "      <td>0.179077</td>\n",
              "      <td>-0.021383</td>\n",
              "      <td>-1.027213</td>\n",
              "      <td>-1.587730</td>\n",
              "      <td>-0.252947</td>\n",
              "      <td>0.588201</td>\n",
              "      <td>0.247445</td>\n",
              "      <td>0.056358</td>\n",
              "      <td>-2.105504</td>\n",
              "      <td>-0.954460</td>\n",
              "      <td>-0.913101</td>\n",
              "      <td>-0.859178</td>\n",
              "      <td>0.463072</td>\n",
              "      <td>0.198814</td>\n",
              "      <td>-1.046393</td>\n",
              "      <td>-0.512970</td>\n",
              "      <td>-0.461206</td>\n",
              "      <td>-0.558183</td>\n",
              "      <td>-0.387591</td>\n",
              "      <td>0.676285</td>\n",
              "      <td>-0.820568</td>\n",
              "      <td>-0.391481</td>\n",
              "      <td>0.229252</td>\n",
              "      <td>-1.221630</td>\n",
              "      <td>...</td>\n",
              "      <td>0.757545</td>\n",
              "      <td>-0.451426</td>\n",
              "      <td>-0.573116</td>\n",
              "      <td>-0.763363</td>\n",
              "      <td>0.282811</td>\n",
              "      <td>-0.554537</td>\n",
              "      <td>-1.276492</td>\n",
              "      <td>0.118825</td>\n",
              "      <td>-0.776310</td>\n",
              "      <td>-0.041442</td>\n",
              "      <td>0.530594</td>\n",
              "      <td>0.117643</td>\n",
              "      <td>-1.054927</td>\n",
              "      <td>0.777896</td>\n",
              "      <td>0.324017</td>\n",
              "      <td>0.289924</td>\n",
              "      <td>0.228813</td>\n",
              "      <td>0.268363</td>\n",
              "      <td>0.545516</td>\n",
              "      <td>0.012648</td>\n",
              "      <td>0.440917</td>\n",
              "      <td>1.155032</td>\n",
              "      <td>-0.290898</td>\n",
              "      <td>0.307650</td>\n",
              "      <td>0.057588</td>\n",
              "      <td>-0.301497</td>\n",
              "      <td>-0.007591</td>\n",
              "      <td>0.762821</td>\n",
              "      <td>0.693275</td>\n",
              "      <td>1.088418</td>\n",
              "      <td>0.365047</td>\n",
              "      <td>-1.133396</td>\n",
              "      <td>1.272128</td>\n",
              "      <td>2.073542</td>\n",
              "      <td>-0.483376</td>\n",
              "      <td>-0.701208</td>\n",
              "      <td>0.029797</td>\n",
              "      <td>-0.717053</td>\n",
              "      <td>1</td>\n",
              "      <td>50003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.327051</td>\n",
              "      <td>-0.112114</td>\n",
              "      <td>0.208217</td>\n",
              "      <td>-0.474224</td>\n",
              "      <td>1.085125</td>\n",
              "      <td>0.461555</td>\n",
              "      <td>0.321976</td>\n",
              "      <td>-0.319322</td>\n",
              "      <td>1.149837</td>\n",
              "      <td>-0.148961</td>\n",
              "      <td>0.168196</td>\n",
              "      <td>1.244772</td>\n",
              "      <td>-0.037300</td>\n",
              "      <td>-0.003884</td>\n",
              "      <td>0.871292</td>\n",
              "      <td>-0.089447</td>\n",
              "      <td>-0.146884</td>\n",
              "      <td>-0.230116</td>\n",
              "      <td>0.372652</td>\n",
              "      <td>0.811372</td>\n",
              "      <td>-0.197816</td>\n",
              "      <td>0.089464</td>\n",
              "      <td>0.247445</td>\n",
              "      <td>1.026112</td>\n",
              "      <td>0.302586</td>\n",
              "      <td>0.147325</td>\n",
              "      <td>-0.072143</td>\n",
              "      <td>0.472651</td>\n",
              "      <td>-0.887169</td>\n",
              "      <td>0.986706</td>\n",
              "      <td>1.037108</td>\n",
              "      <td>-0.323318</td>\n",
              "      <td>-0.139617</td>\n",
              "      <td>0.416943</td>\n",
              "      <td>0.617230</td>\n",
              "      <td>0.327794</td>\n",
              "      <td>-1.241008</td>\n",
              "      <td>1.071588</td>\n",
              "      <td>1.521595</td>\n",
              "      <td>0.660391</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.635823</td>\n",
              "      <td>1.581960</td>\n",
              "      <td>-0.868179</td>\n",
              "      <td>-0.076329</td>\n",
              "      <td>0.815834</td>\n",
              "      <td>-0.306342</td>\n",
              "      <td>0.315850</td>\n",
              "      <td>0.807402</td>\n",
              "      <td>-0.238513</td>\n",
              "      <td>-0.120628</td>\n",
              "      <td>0.387567</td>\n",
              "      <td>-1.813738</td>\n",
              "      <td>-0.823482</td>\n",
              "      <td>0.131382</td>\n",
              "      <td>0.215356</td>\n",
              "      <td>-0.067209</td>\n",
              "      <td>1.408767</td>\n",
              "      <td>0.833187</td>\n",
              "      <td>-0.296458</td>\n",
              "      <td>0.022799</td>\n",
              "      <td>0.668122</td>\n",
              "      <td>1.079538</td>\n",
              "      <td>0.507204</td>\n",
              "      <td>0.060677</td>\n",
              "      <td>-0.567144</td>\n",
              "      <td>-0.343508</td>\n",
              "      <td>-0.417350</td>\n",
              "      <td>-1.329119</td>\n",
              "      <td>-0.228237</td>\n",
              "      <td>-0.457645</td>\n",
              "      <td>0.768118</td>\n",
              "      <td>-0.372635</td>\n",
              "      <td>0.737403</td>\n",
              "      <td>0.353952</td>\n",
              "      <td>0.072344</td>\n",
              "      <td>0.579115</td>\n",
              "      <td>-0.632130</td>\n",
              "      <td>0.465301</td>\n",
              "      <td>1</td>\n",
              "      <td>50004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.575862</td>\n",
              "      <td>-0.835441</td>\n",
              "      <td>1.166302</td>\n",
              "      <td>-0.603246</td>\n",
              "      <td>0.467322</td>\n",
              "      <td>1.037856</td>\n",
              "      <td>-0.189336</td>\n",
              "      <td>0.995846</td>\n",
              "      <td>0.619497</td>\n",
              "      <td>2.296125</td>\n",
              "      <td>1.471944</td>\n",
              "      <td>1.052196</td>\n",
              "      <td>1.060204</td>\n",
              "      <td>1.046670</td>\n",
              "      <td>1.077764</td>\n",
              "      <td>0.134871</td>\n",
              "      <td>0.519744</td>\n",
              "      <td>-0.751950</td>\n",
              "      <td>0.861809</td>\n",
              "      <td>2.320705</td>\n",
              "      <td>1.333578</td>\n",
              "      <td>1.006062</td>\n",
              "      <td>0.853225</td>\n",
              "      <td>-1.153198</td>\n",
              "      <td>-0.647836</td>\n",
              "      <td>0.449776</td>\n",
              "      <td>0.488495</td>\n",
              "      <td>0.289920</td>\n",
              "      <td>0.009177</td>\n",
              "      <td>1.041232</td>\n",
              "      <td>1.709313</td>\n",
              "      <td>0.810644</td>\n",
              "      <td>0.487796</td>\n",
              "      <td>0.897639</td>\n",
              "      <td>-0.064301</td>\n",
              "      <td>-0.292598</td>\n",
              "      <td>0.242494</td>\n",
              "      <td>1.266201</td>\n",
              "      <td>-1.495805</td>\n",
              "      <td>0.034981</td>\n",
              "      <td>...</td>\n",
              "      <td>0.199757</td>\n",
              "      <td>-0.888097</td>\n",
              "      <td>0.220168</td>\n",
              "      <td>-0.188753</td>\n",
              "      <td>1.500532</td>\n",
              "      <td>0.715395</td>\n",
              "      <td>0.126398</td>\n",
              "      <td>-0.326726</td>\n",
              "      <td>-0.044779</td>\n",
              "      <td>-0.374854</td>\n",
              "      <td>-0.199266</td>\n",
              "      <td>-0.684517</td>\n",
              "      <td>-0.476315</td>\n",
              "      <td>-0.854552</td>\n",
              "      <td>0.573937</td>\n",
              "      <td>1.939430</td>\n",
              "      <td>-0.275126</td>\n",
              "      <td>0.107724</td>\n",
              "      <td>-0.424258</td>\n",
              "      <td>0.472010</td>\n",
              "      <td>0.568720</td>\n",
              "      <td>-0.522622</td>\n",
              "      <td>0.694428</td>\n",
              "      <td>0.109190</td>\n",
              "      <td>-0.235336</td>\n",
              "      <td>-0.260987</td>\n",
              "      <td>-0.730695</td>\n",
              "      <td>-0.084222</td>\n",
              "      <td>-1.003145</td>\n",
              "      <td>-0.973000</td>\n",
              "      <td>-0.140066</td>\n",
              "      <td>-0.247668</td>\n",
              "      <td>0.132321</td>\n",
              "      <td>-1.280929</td>\n",
              "      <td>-0.502123</td>\n",
              "      <td>0.688965</td>\n",
              "      <td>-0.058915</td>\n",
              "      <td>0.077953</td>\n",
              "      <td>1</td>\n",
              "      <td>50006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.826273</td>\n",
              "      <td>-0.599193</td>\n",
              "      <td>-1.665370</td>\n",
              "      <td>-0.194062</td>\n",
              "      <td>-0.347522</td>\n",
              "      <td>0.914058</td>\n",
              "      <td>-1.178854</td>\n",
              "      <td>-0.566488</td>\n",
              "      <td>-0.604365</td>\n",
              "      <td>-0.252324</td>\n",
              "      <td>-1.375505</td>\n",
              "      <td>-0.893835</td>\n",
              "      <td>-1.001057</td>\n",
              "      <td>-0.232717</td>\n",
              "      <td>0.364034</td>\n",
              "      <td>-1.194780</td>\n",
              "      <td>-0.803709</td>\n",
              "      <td>-0.357676</td>\n",
              "      <td>0.046547</td>\n",
              "      <td>0.803184</td>\n",
              "      <td>0.525002</td>\n",
              "      <td>-0.992256</td>\n",
              "      <td>-0.522670</td>\n",
              "      <td>-0.441694</td>\n",
              "      <td>-1.157753</td>\n",
              "      <td>-1.099513</td>\n",
              "      <td>-1.504506</td>\n",
              "      <td>-1.755263</td>\n",
              "      <td>-0.463789</td>\n",
              "      <td>-1.396053</td>\n",
              "      <td>-0.822325</td>\n",
              "      <td>-0.406291</td>\n",
              "      <td>-1.293553</td>\n",
              "      <td>-1.083516</td>\n",
              "      <td>-1.082228</td>\n",
              "      <td>-1.307435</td>\n",
              "      <td>-1.316208</td>\n",
              "      <td>0.626760</td>\n",
              "      <td>-0.224711</td>\n",
              "      <td>-1.178199</td>\n",
              "      <td>...</td>\n",
              "      <td>2.177630</td>\n",
              "      <td>0.033763</td>\n",
              "      <td>1.443953</td>\n",
              "      <td>1.135348</td>\n",
              "      <td>3.394283</td>\n",
              "      <td>1.269698</td>\n",
              "      <td>0.951534</td>\n",
              "      <td>0.726393</td>\n",
              "      <td>1.869268</td>\n",
              "      <td>1.186623</td>\n",
              "      <td>1.157391</td>\n",
              "      <td>1.938856</td>\n",
              "      <td>1.606689</td>\n",
              "      <td>-0.579783</td>\n",
              "      <td>3.942426</td>\n",
              "      <td>3.622417</td>\n",
              "      <td>1.630008</td>\n",
              "      <td>1.895473</td>\n",
              "      <td>1.774648</td>\n",
              "      <td>2.202870</td>\n",
              "      <td>1.818351</td>\n",
              "      <td>1.029208</td>\n",
              "      <td>1.762563</td>\n",
              "      <td>0.585494</td>\n",
              "      <td>1.462587</td>\n",
              "      <td>1.422426</td>\n",
              "      <td>2.920983</td>\n",
              "      <td>2.423539</td>\n",
              "      <td>2.536299</td>\n",
              "      <td>2.376805</td>\n",
              "      <td>0.283413</td>\n",
              "      <td>1.486517</td>\n",
              "      <td>2.932588</td>\n",
              "      <td>1.285750</td>\n",
              "      <td>2.217554</td>\n",
              "      <td>2.007167</td>\n",
              "      <td>1.314982</td>\n",
              "      <td>1.509835</td>\n",
              "      <td>1</td>\n",
              "      <td>50007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.530438</td>\n",
              "      <td>-0.619609</td>\n",
              "      <td>-1.196973</td>\n",
              "      <td>-1.388436</td>\n",
              "      <td>0.257966</td>\n",
              "      <td>-0.731604</td>\n",
              "      <td>-1.138390</td>\n",
              "      <td>-0.319322</td>\n",
              "      <td>-1.121107</td>\n",
              "      <td>-1.663773</td>\n",
              "      <td>-0.842275</td>\n",
              "      <td>-0.809371</td>\n",
              "      <td>-0.548681</td>\n",
              "      <td>-1.311008</td>\n",
              "      <td>-1.308135</td>\n",
              "      <td>-1.155768</td>\n",
              "      <td>0.718262</td>\n",
              "      <td>-1.308573</td>\n",
              "      <td>-0.422726</td>\n",
              "      <td>-0.285828</td>\n",
              "      <td>-0.436714</td>\n",
              "      <td>-1.042804</td>\n",
              "      <td>-1.286340</td>\n",
              "      <td>-0.555008</td>\n",
              "      <td>0.361320</td>\n",
              "      <td>-1.682811</td>\n",
              "      <td>-0.851567</td>\n",
              "      <td>-0.890804</td>\n",
              "      <td>-0.944383</td>\n",
              "      <td>-0.534552</td>\n",
              "      <td>-1.226985</td>\n",
              "      <td>-1.571862</td>\n",
              "      <td>-1.350304</td>\n",
              "      <td>-1.104117</td>\n",
              "      <td>-0.907477</td>\n",
              "      <td>-0.265791</td>\n",
              "      <td>-1.613592</td>\n",
              "      <td>-0.467936</td>\n",
              "      <td>-0.340616</td>\n",
              "      <td>-1.988916</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085922</td>\n",
              "      <td>0.488078</td>\n",
              "      <td>0.379792</td>\n",
              "      <td>0.685653</td>\n",
              "      <td>0.226475</td>\n",
              "      <td>-0.467669</td>\n",
              "      <td>-1.295280</td>\n",
              "      <td>-0.083698</td>\n",
              "      <td>0.509956</td>\n",
              "      <td>0.682338</td>\n",
              "      <td>-1.459168</td>\n",
              "      <td>0.136578</td>\n",
              "      <td>0.651979</td>\n",
              "      <td>0.309173</td>\n",
              "      <td>-0.740860</td>\n",
              "      <td>-0.879686</td>\n",
              "      <td>-0.938849</td>\n",
              "      <td>-0.850923</td>\n",
              "      <td>-0.085965</td>\n",
              "      <td>-0.078717</td>\n",
              "      <td>-0.595709</td>\n",
              "      <td>-0.413574</td>\n",
              "      <td>0.592415</td>\n",
              "      <td>1.075029</td>\n",
              "      <td>0.936361</td>\n",
              "      <td>0.318155</td>\n",
              "      <td>0.341910</td>\n",
              "      <td>-0.276732</td>\n",
              "      <td>0.064971</td>\n",
              "      <td>0.233684</td>\n",
              "      <td>0.066571</td>\n",
              "      <td>0.914301</td>\n",
              "      <td>-0.170221</td>\n",
              "      <td>-0.569375</td>\n",
              "      <td>0.657523</td>\n",
              "      <td>-0.561054</td>\n",
              "      <td>0.275460</td>\n",
              "      <td>-0.152715</td>\n",
              "      <td>1</td>\n",
              "      <td>50008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 526 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...       523  Class  subject_ids\n",
              "0 -1.562779 -0.485444 -0.022433  ... -0.717053      1        50003\n",
              "1 -0.327051 -0.112114  0.208217  ...  0.465301      1        50004\n",
              "2  0.575862 -0.835441  1.166302  ...  0.077953      1        50006\n",
              "3 -0.826273 -0.599193 -1.665370  ...  1.509835      1        50007\n",
              "4 -0.530438 -0.619609 -1.196973  ... -0.152715      1        50008\n",
              "\n",
              "[5 rows x 526 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpztbxC3o94h"
      },
      "source": [
        "## MinMax scaling the raw structural data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKgPKaohkLL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2b2f2c35-88ac-4146-e15c-16b780ae531f"
      },
      "source": [
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\r\n",
        "str_sc_mm = min_max_scaler.fit_transform(str_unsc.iloc[:,:-2])\r\n",
        "\r\n",
        "str_sc_mm = pd.DataFrame(str_sc_mm)\r\n",
        "cols = str_unsc.iloc[:,-2:]\r\n",
        "str_sc_mm = pd.concat([str_sc_mm,cols],axis=1)\r\n",
        "str_sc_mm.head()\r\n",
        "#str_sc_mm = str_unsc"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>486</th>\n",
              "      <th>487</th>\n",
              "      <th>488</th>\n",
              "      <th>489</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "      <th>501</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>520</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "      <th>Class</th>\n",
              "      <th>Subjects_IDs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.253231</td>\n",
              "      <td>-0.113674</td>\n",
              "      <td>0.100280</td>\n",
              "      <td>-0.462110</td>\n",
              "      <td>0.085619</td>\n",
              "      <td>-0.062258</td>\n",
              "      <td>-0.071174</td>\n",
              "      <td>0.297638</td>\n",
              "      <td>-0.355</td>\n",
              "      <td>0.130699</td>\n",
              "      <td>-0.293931</td>\n",
              "      <td>0.118746</td>\n",
              "      <td>-0.521056</td>\n",
              "      <td>-0.249274</td>\n",
              "      <td>0.095216</td>\n",
              "      <td>-0.167271</td>\n",
              "      <td>-0.032767</td>\n",
              "      <td>-0.326765</td>\n",
              "      <td>-0.225467</td>\n",
              "      <td>-0.497051</td>\n",
              "      <td>-0.036504</td>\n",
              "      <td>0.152421</td>\n",
              "      <td>0.256236</td>\n",
              "      <td>0.209026</td>\n",
              "      <td>-0.079975</td>\n",
              "      <td>-0.146484</td>\n",
              "      <td>-0.271758</td>\n",
              "      <td>-0.077328</td>\n",
              "      <td>0.105229</td>\n",
              "      <td>0.168112</td>\n",
              "      <td>-0.364733</td>\n",
              "      <td>-0.211525</td>\n",
              "      <td>-0.111658</td>\n",
              "      <td>-0.016687</td>\n",
              "      <td>-0.303754</td>\n",
              "      <td>0.265636</td>\n",
              "      <td>-0.284042</td>\n",
              "      <td>-0.254425</td>\n",
              "      <td>-0.073704</td>\n",
              "      <td>-0.339034</td>\n",
              "      <td>...</td>\n",
              "      <td>0.211547</td>\n",
              "      <td>-0.314074</td>\n",
              "      <td>-0.338776</td>\n",
              "      <td>-0.388988</td>\n",
              "      <td>0.060589</td>\n",
              "      <td>-0.013628</td>\n",
              "      <td>-0.313131</td>\n",
              "      <td>-0.272289</td>\n",
              "      <td>-0.322049</td>\n",
              "      <td>0.230154</td>\n",
              "      <td>0.320767</td>\n",
              "      <td>-0.054933</td>\n",
              "      <td>-0.654723</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>-0.115942</td>\n",
              "      <td>-0.276154</td>\n",
              "      <td>-0.250394</td>\n",
              "      <td>-0.119505</td>\n",
              "      <td>-0.092854</td>\n",
              "      <td>0.095761</td>\n",
              "      <td>-0.023904</td>\n",
              "      <td>0.029552</td>\n",
              "      <td>-0.129845</td>\n",
              "      <td>0.023053</td>\n",
              "      <td>-0.014366</td>\n",
              "      <td>0.003281</td>\n",
              "      <td>-0.135464</td>\n",
              "      <td>0.273369</td>\n",
              "      <td>-0.230924</td>\n",
              "      <td>0.029491</td>\n",
              "      <td>0.052903</td>\n",
              "      <td>-0.465366</td>\n",
              "      <td>0.143987</td>\n",
              "      <td>-0.105828</td>\n",
              "      <td>-0.129249</td>\n",
              "      <td>-0.411157</td>\n",
              "      <td>0.057225</td>\n",
              "      <td>-0.037591</td>\n",
              "      <td>1</td>\n",
              "      <td>50003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.130685</td>\n",
              "      <td>-0.008237</td>\n",
              "      <td>0.173109</td>\n",
              "      <td>-0.453195</td>\n",
              "      <td>0.521070</td>\n",
              "      <td>0.190292</td>\n",
              "      <td>0.291815</td>\n",
              "      <td>-0.030971</td>\n",
              "      <td>0.473</td>\n",
              "      <td>0.165957</td>\n",
              "      <td>-0.144784</td>\n",
              "      <td>0.509343</td>\n",
              "      <td>-0.068510</td>\n",
              "      <td>0.043579</td>\n",
              "      <td>0.275626</td>\n",
              "      <td>-0.011911</td>\n",
              "      <td>-0.137781</td>\n",
              "      <td>-0.385878</td>\n",
              "      <td>0.185748</td>\n",
              "      <td>0.243471</td>\n",
              "      <td>-0.017995</td>\n",
              "      <td>-0.024507</td>\n",
              "      <td>0.256236</td>\n",
              "      <td>0.500396</td>\n",
              "      <td>0.488035</td>\n",
              "      <td>0.202148</td>\n",
              "      <td>0.019538</td>\n",
              "      <td>0.321410</td>\n",
              "      <td>-0.351840</td>\n",
              "      <td>0.406857</td>\n",
              "      <td>0.350948</td>\n",
              "      <td>-0.144062</td>\n",
              "      <td>-0.011313</td>\n",
              "      <td>0.321812</td>\n",
              "      <td>-0.042093</td>\n",
              "      <td>0.143241</td>\n",
              "      <td>-0.435613</td>\n",
              "      <td>0.211283</td>\n",
              "      <td>0.344160</td>\n",
              "      <td>0.314889</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.513141</td>\n",
              "      <td>0.368889</td>\n",
              "      <td>-0.421769</td>\n",
              "      <td>-0.193606</td>\n",
              "      <td>0.202539</td>\n",
              "      <td>0.064244</td>\n",
              "      <td>0.081974</td>\n",
              "      <td>-0.108434</td>\n",
              "      <td>-0.175058</td>\n",
              "      <td>0.208452</td>\n",
              "      <td>0.298082</td>\n",
              "      <td>-0.668215</td>\n",
              "      <td>-0.602606</td>\n",
              "      <td>-0.078947</td>\n",
              "      <td>-0.144928</td>\n",
              "      <td>-0.363562</td>\n",
              "      <td>0.051969</td>\n",
              "      <td>0.030220</td>\n",
              "      <td>-0.310647</td>\n",
              "      <td>0.098901</td>\n",
              "      <td>0.039841</td>\n",
              "      <td>0.012393</td>\n",
              "      <td>0.084948</td>\n",
              "      <td>-0.046729</td>\n",
              "      <td>-0.164897</td>\n",
              "      <td>-0.007528</td>\n",
              "      <td>-0.238965</td>\n",
              "      <td>-0.301587</td>\n",
              "      <td>-0.407631</td>\n",
              "      <td>-0.300268</td>\n",
              "      <td>0.188817</td>\n",
              "      <td>-0.239675</td>\n",
              "      <td>0.023734</td>\n",
              "      <td>-0.417178</td>\n",
              "      <td>0.013978</td>\n",
              "      <td>-0.061983</td>\n",
              "      <td>-0.110983</td>\n",
              "      <td>0.300935</td>\n",
              "      <td>1</td>\n",
              "      <td>50004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.411202</td>\n",
              "      <td>-0.212521</td>\n",
              "      <td>0.475630</td>\n",
              "      <td>-0.487865</td>\n",
              "      <td>0.319732</td>\n",
              "      <td>0.380232</td>\n",
              "      <td>0.126928</td>\n",
              "      <td>0.421522</td>\n",
              "      <td>0.317</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.243157</td>\n",
              "      <td>0.440627</td>\n",
              "      <td>0.282212</td>\n",
              "      <td>0.395700</td>\n",
              "      <td>0.349431</td>\n",
              "      <td>0.059555</td>\n",
              "      <td>0.076984</td>\n",
              "      <td>-0.533662</td>\n",
              "      <td>0.329439</td>\n",
              "      <td>0.709351</td>\n",
              "      <td>0.496144</td>\n",
              "      <td>0.300658</td>\n",
              "      <td>0.469388</td>\n",
              "      <td>-0.154394</td>\n",
              "      <td>0.263854</td>\n",
              "      <td>0.297852</td>\n",
              "      <td>0.213736</td>\n",
              "      <td>0.266702</td>\n",
              "      <td>-0.048418</td>\n",
              "      <td>0.423379</td>\n",
              "      <td>0.581850</td>\n",
              "      <td>0.259311</td>\n",
              "      <td>0.184456</td>\n",
              "      <td>0.488677</td>\n",
              "      <td>-0.219568</td>\n",
              "      <td>-0.074647</td>\n",
              "      <td>0.099199</td>\n",
              "      <td>0.273230</td>\n",
              "      <td>-0.631480</td>\n",
              "      <td>0.097586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042654</td>\n",
              "      <td>-0.460741</td>\n",
              "      <td>-0.115646</td>\n",
              "      <td>-0.225577</td>\n",
              "      <td>0.384882</td>\n",
              "      <td>0.384815</td>\n",
              "      <td>0.034965</td>\n",
              "      <td>-0.378313</td>\n",
              "      <td>-0.122106</td>\n",
              "      <td>0.138778</td>\n",
              "      <td>0.205004</td>\n",
              "      <td>-0.309647</td>\n",
              "      <td>-0.524430</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>-0.049275</td>\n",
              "      <td>0.127561</td>\n",
              "      <td>-0.379528</td>\n",
              "      <td>-0.162088</td>\n",
              "      <td>-0.343704</td>\n",
              "      <td>0.237834</td>\n",
              "      <td>0.011952</td>\n",
              "      <td>-0.351764</td>\n",
              "      <td>0.135336</td>\n",
              "      <td>-0.033022</td>\n",
              "      <td>-0.084947</td>\n",
              "      <td>0.013704</td>\n",
              "      <td>-0.318113</td>\n",
              "      <td>0.040564</td>\n",
              "      <td>-0.556225</td>\n",
              "      <td>-0.410188</td>\n",
              "      <td>-0.117419</td>\n",
              "      <td>-0.202602</td>\n",
              "      <td>-0.112342</td>\n",
              "      <td>-0.713190</td>\n",
              "      <td>-0.134081</td>\n",
              "      <td>-0.032025</td>\n",
              "      <td>0.034682</td>\n",
              "      <td>0.190031</td>\n",
              "      <td>1</td>\n",
              "      <td>50006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.024414</td>\n",
              "      <td>-0.145799</td>\n",
              "      <td>-0.418487</td>\n",
              "      <td>-0.377910</td>\n",
              "      <td>0.054181</td>\n",
              "      <td>0.339430</td>\n",
              "      <td>-0.192171</td>\n",
              "      <td>-0.116010</td>\n",
              "      <td>-0.043</td>\n",
              "      <td>0.130699</td>\n",
              "      <td>-0.604125</td>\n",
              "      <td>-0.253767</td>\n",
              "      <td>-0.376493</td>\n",
              "      <td>-0.033120</td>\n",
              "      <td>0.094305</td>\n",
              "      <td>-0.364060</td>\n",
              "      <td>-0.349388</td>\n",
              "      <td>-0.422003</td>\n",
              "      <td>0.089953</td>\n",
              "      <td>0.240944</td>\n",
              "      <td>0.224679</td>\n",
              "      <td>-0.408249</td>\n",
              "      <td>-0.014739</td>\n",
              "      <td>0.059382</td>\n",
              "      <td>0.143577</td>\n",
              "      <td>-0.192383</td>\n",
              "      <td>-0.476613</td>\n",
              "      <td>-0.345608</td>\n",
              "      <td>-0.208522</td>\n",
              "      <td>-0.315159</td>\n",
              "      <td>-0.287766</td>\n",
              "      <td>-0.173577</td>\n",
              "      <td>-0.371372</td>\n",
              "      <td>-0.199046</td>\n",
              "      <td>-0.484642</td>\n",
              "      <td>-0.431069</td>\n",
              "      <td>-0.462723</td>\n",
              "      <td>0.069690</td>\n",
              "      <td>-0.220487</td>\n",
              "      <td>-0.323944</td>\n",
              "      <td>...</td>\n",
              "      <td>0.641534</td>\n",
              "      <td>-0.151111</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>0.150977</td>\n",
              "      <td>0.889209</td>\n",
              "      <td>0.558728</td>\n",
              "      <td>0.239705</td>\n",
              "      <td>-0.127711</td>\n",
              "      <td>0.401042</td>\n",
              "      <td>0.566724</td>\n",
              "      <td>0.420183</td>\n",
              "      <td>0.523367</td>\n",
              "      <td>-0.055375</td>\n",
              "      <td>-0.310526</td>\n",
              "      <td>0.849275</td>\n",
              "      <td>0.539470</td>\n",
              "      <td>0.108661</td>\n",
              "      <td>0.311813</td>\n",
              "      <td>0.225085</td>\n",
              "      <td>0.773155</td>\n",
              "      <td>0.362550</td>\n",
              "      <td>0.000953</td>\n",
              "      <td>0.422804</td>\n",
              "      <td>0.101558</td>\n",
              "      <td>0.324172</td>\n",
              "      <td>0.446825</td>\n",
              "      <td>0.604262</td>\n",
              "      <td>0.729806</td>\n",
              "      <td>0.122490</td>\n",
              "      <td>0.304290</td>\n",
              "      <td>0.025376</td>\n",
              "      <td>0.311870</td>\n",
              "      <td>0.517405</td>\n",
              "      <td>-0.248466</td>\n",
              "      <td>0.566868</td>\n",
              "      <td>0.327479</td>\n",
              "      <td>0.383815</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1</td>\n",
              "      <td>50007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.067496</td>\n",
              "      <td>-0.151565</td>\n",
              "      <td>-0.270588</td>\n",
              "      <td>-0.698861</td>\n",
              "      <td>0.251505</td>\n",
              "      <td>-0.202955</td>\n",
              "      <td>-0.179122</td>\n",
              "      <td>-0.030971</td>\n",
              "      <td>-0.195</td>\n",
              "      <td>-0.350760</td>\n",
              "      <td>-0.445458</td>\n",
              "      <td>-0.223629</td>\n",
              "      <td>-0.231930</td>\n",
              "      <td>-0.394538</td>\n",
              "      <td>-0.503417</td>\n",
              "      <td>-0.351631</td>\n",
              "      <td>0.140940</td>\n",
              "      <td>-0.691297</td>\n",
              "      <td>-0.047897</td>\n",
              "      <td>-0.095198</td>\n",
              "      <td>-0.098201</td>\n",
              "      <td>-0.426181</td>\n",
              "      <td>-0.283447</td>\n",
              "      <td>0.025337</td>\n",
              "      <td>0.501889</td>\n",
              "      <td>-0.376953</td>\n",
              "      <td>-0.250444</td>\n",
              "      <td>-0.086796</td>\n",
              "      <td>-0.371207</td>\n",
              "      <td>-0.054110</td>\n",
              "      <td>-0.426766</td>\n",
              "      <td>-0.588194</td>\n",
              "      <td>-0.389080</td>\n",
              "      <td>-0.206198</td>\n",
              "      <td>-0.439135</td>\n",
              "      <td>-0.065232</td>\n",
              "      <td>-0.569932</td>\n",
              "      <td>-0.278761</td>\n",
              "      <td>-0.257964</td>\n",
              "      <td>-0.605634</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008186</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>-0.070748</td>\n",
              "      <td>0.023091</td>\n",
              "      <td>0.045586</td>\n",
              "      <td>0.013628</td>\n",
              "      <td>-0.317793</td>\n",
              "      <td>-0.320482</td>\n",
              "      <td>0.029514</td>\n",
              "      <td>0.428517</td>\n",
              "      <td>0.005171</td>\n",
              "      <td>-0.048920</td>\n",
              "      <td>-0.270358</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>-0.400000</td>\n",
              "      <td>-0.562415</td>\n",
              "      <td>-0.549606</td>\n",
              "      <td>-0.416209</td>\n",
              "      <td>-0.256198</td>\n",
              "      <td>0.067504</td>\n",
              "      <td>-0.314741</td>\n",
              "      <td>-0.326978</td>\n",
              "      <td>0.107881</td>\n",
              "      <td>0.239875</td>\n",
              "      <td>0.197377</td>\n",
              "      <td>0.162710</td>\n",
              "      <td>-0.047184</td>\n",
              "      <td>-0.012346</td>\n",
              "      <td>-0.351406</td>\n",
              "      <td>-0.152815</td>\n",
              "      <td>-0.047742</td>\n",
              "      <td>0.142114</td>\n",
              "      <td>-0.180380</td>\n",
              "      <td>-0.584356</td>\n",
              "      <td>0.164797</td>\n",
              "      <td>-0.372934</td>\n",
              "      <td>0.119653</td>\n",
              "      <td>0.123988</td>\n",
              "      <td>1</td>\n",
              "      <td>50008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 526 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...       523  Class  Subjects_IDs\n",
              "0 -0.253231 -0.113674  0.100280  ... -0.037591      1         50003\n",
              "1  0.130685 -0.008237  0.173109  ...  0.300935      1         50004\n",
              "2  0.411202 -0.212521  0.475630  ...  0.190031      1         50006\n",
              "3 -0.024414 -0.145799 -0.418487  ...  0.600000      1         50007\n",
              "4  0.067496 -0.151565 -0.270588  ...  0.123988      1         50008\n",
              "\n",
              "[5 rows x 526 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe9jfU0NWYtA"
      },
      "source": [
        "# Organizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a_h0YN8_eA7"
      },
      "source": [
        "#import numpy as np\r\n",
        "\r\n",
        "#functional\r\n",
        "x1 = func_aal.iloc[:,:-2]\r\n",
        "y1 = func_aal.iloc[:,-2]\r\n",
        "# x1 = np.asarray(x1.values)\r\n",
        "# y1=np.asarray(y1)\r\n",
        "# y1=y1.astype('int')\r\n",
        "\r\n",
        "#structural (standard scaled)\r\n",
        "x2= str_sc_std.iloc[:,:-2]\r\n",
        "y2=str_sc_std.iloc[:,-2]\r\n",
        "# x2 = np.asarray(x2.values)\r\n",
        "# y2=np.asarray(y2)\r\n",
        "\r\n",
        "#structural (to be minmax scaled)\r\n",
        "x3 = str_sc_mm.iloc[:,:-2]\r\n",
        "y3 = str_sc_mm.iloc[:,-2]\r\n",
        "# x3 = np.asarray(x3.values)\r\n",
        "# y3=np.asarray(y3)\r\n",
        "\r\n",
        "\r\n",
        "# create combined functional and structural data (mm)\r\n",
        "f1 =  func_aal.iloc[:,:-2]\r\n",
        "combined = pd.concat([f1,str_sc_mm], axis= 1)\r\n",
        "x4 = combined.iloc[:,:-2]\r\n",
        "y4 = combined.iloc[:,-2]\r\n",
        "# x4 = np.asarray(x4.values)\r\n",
        "# y4 = np.asarray(y4)\r\n",
        "\r\n",
        "# create combined functional and structural data (std)\r\n",
        "f2 = func_aal.iloc[:,:-2]\r\n",
        "combined2 = pd.concat([f2, str_sc_std], axis=1)\r\n",
        "x5 = combined2.iloc[:,:-2]\r\n",
        "y5 = combined2.iloc[:,-2]\r\n",
        "# x5 = np.asarray(x5.values)\r\n",
        "# y5 = np.asarray(y5)\r\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z3iWjsVFoIV",
        "outputId": "73c59520-ba83-400c-d9c4-4770a6286420"
      },
      "source": [
        "print (x1, y1)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            0         1         2  ...      6783      6784      6785\n",
            "0    0.707107  0.599674  0.707107  ...  0.440268  0.652267  0.707107\n",
            "1    0.707107  0.279840  0.707107  ...  0.414008  0.473352  0.707107\n",
            "2    0.707107  0.494872  0.707107  ...  0.137485  0.126701  0.707107\n",
            "3    0.707107 -0.165482  0.707107  ...  0.375122  0.347415  0.707107\n",
            "4    0.707107  0.519511  0.707107  ...  0.280859  0.311029  0.707107\n",
            "..        ...       ...       ...  ...       ...       ...       ...\n",
            "719  0.707107  0.260329  0.707107  ...  0.333951  0.571155  0.707107\n",
            "720  0.707107  0.394883  0.707107  ... -0.002108  0.151044  0.707107\n",
            "721  0.707107  0.439465  0.707107  ... -0.430771  0.000000  0.707107\n",
            "722  0.707107  0.533167  0.707107  ...  0.365517  0.469919  0.707107\n",
            "723  0.707107  0.349312  0.707107  ...  0.112900  0.128663  0.707107\n",
            "\n",
            "[724 rows x 6786 columns] 0      1\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "719    1\n",
            "720    1\n",
            "721    1\n",
            "722    1\n",
            "723    1\n",
            "Name: Class, Length: 724, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRGpIlz1JtXA"
      },
      "source": [
        "## checking whether the reading process is accurately done \r\n",
        "#str_sc_std.shape\r\n",
        "#str_sc_std.shape == str_unsc.shape\r\n",
        "#func_aal.shape"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NKaBUl4pB39"
      },
      "source": [
        "# Test-train split "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToljTugIpC4B"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# x1_train, x1_test, y1_train, y1_test = train_test_split(func_aal.iloc[:,:-2], func_aal[\"Class\"], test_size=0.3, random_state=30)\n",
        "# x2_train, x2_test, y2_train, y2_test = train_test_split(str_sc_std.iloc[:,:-2], str_sc_std[\"Class\"], test_size=0.3, random_state=30)\n",
        "# x3_train, x3_test, y3_train, y3_test = train_test_split(str_sc_mm.iloc[:,:-2], str_sc_mm[\"Class\"], test_size=0.3, random_state=30)\n",
        "\n",
        "# # create combined functional and structural data (std)\n",
        "# combined = func_aal.iloc[:,:-2].join(str_sc_mm)\n",
        "\n",
        "# x4_train, x4_test, y4_train, y4_test = train_test_split(combined.iloc[:,:-2], combined[\"Class\"], test_size=0.3, random_state=30)\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaRpILl5e4ml"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.3, random_state=30)\r\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.3, random_state=30)\r\n",
        "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=0.3, random_state=30)\r\n",
        "x4_train, x4_test, y4_train, y4_test = train_test_split(x4, y4, test_size=0.3, random_state=30)\r\n",
        "x5_train, x5_test, y5_train, y5_test = train_test_split(x5, y5, test_size=0.3, random_state=30)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "K05Y-owGmFfQ",
        "outputId": "55da341f-aa26-4080-f3ff-8c860e7d814c"
      },
      "source": [
        "#combined.head()\r\n",
        "x3_test"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>484</th>\n",
              "      <th>485</th>\n",
              "      <th>486</th>\n",
              "      <th>487</th>\n",
              "      <th>488</th>\n",
              "      <th>489</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "      <th>501</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "      <th>513</th>\n",
              "      <th>514</th>\n",
              "      <th>515</th>\n",
              "      <th>516</th>\n",
              "      <th>517</th>\n",
              "      <th>518</th>\n",
              "      <th>519</th>\n",
              "      <th>520</th>\n",
              "      <th>521</th>\n",
              "      <th>522</th>\n",
              "      <th>523</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0.564385</td>\n",
              "      <td>0.016474</td>\n",
              "      <td>0.484594</td>\n",
              "      <td>-0.253096</td>\n",
              "      <td>0.296990</td>\n",
              "      <td>0.682730</td>\n",
              "      <td>0.032028</td>\n",
              "      <td>0.366929</td>\n",
              "      <td>0.302</td>\n",
              "      <td>0.411550</td>\n",
              "      <td>0.441491</td>\n",
              "      <td>-0.033153</td>\n",
              "      <td>0.389063</td>\n",
              "      <td>0.401511</td>\n",
              "      <td>0.782232</td>\n",
              "      <td>0.326774</td>\n",
              "      <td>-0.279905</td>\n",
              "      <td>-0.191024</td>\n",
              "      <td>0.043224</td>\n",
              "      <td>0.296546</td>\n",
              "      <td>0.844730</td>\n",
              "      <td>0.395099</td>\n",
              "      <td>0.824263</td>\n",
              "      <td>0.101346</td>\n",
              "      <td>0.258816</td>\n",
              "      <td>0.493164</td>\n",
              "      <td>0.329781</td>\n",
              "      <td>-0.007891</td>\n",
              "      <td>0.154293</td>\n",
              "      <td>0.410987</td>\n",
              "      <td>0.916140</td>\n",
              "      <td>0.159522</td>\n",
              "      <td>0.183473</td>\n",
              "      <td>0.574493</td>\n",
              "      <td>0.485779</td>\n",
              "      <td>0.323470</td>\n",
              "      <td>0.566235</td>\n",
              "      <td>0.544248</td>\n",
              "      <td>-0.279825</td>\n",
              "      <td>-0.152918</td>\n",
              "      <td>...</td>\n",
              "      <td>0.359489</td>\n",
              "      <td>-0.741255</td>\n",
              "      <td>-0.540715</td>\n",
              "      <td>-0.417778</td>\n",
              "      <td>-0.368707</td>\n",
              "      <td>-0.246892</td>\n",
              "      <td>0.022504</td>\n",
              "      <td>0.338092</td>\n",
              "      <td>-0.003108</td>\n",
              "      <td>-0.387952</td>\n",
              "      <td>-0.254919</td>\n",
              "      <td>-0.019227</td>\n",
              "      <td>0.094579</td>\n",
              "      <td>-0.485652</td>\n",
              "      <td>-0.381107</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>-0.382609</td>\n",
              "      <td>-0.683147</td>\n",
              "      <td>-0.417323</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.302868</td>\n",
              "      <td>-0.023548</td>\n",
              "      <td>-0.131474</td>\n",
              "      <td>-0.239276</td>\n",
              "      <td>-0.203811</td>\n",
              "      <td>-0.146417</td>\n",
              "      <td>-0.325422</td>\n",
              "      <td>-0.125265</td>\n",
              "      <td>-0.226788</td>\n",
              "      <td>-0.394709</td>\n",
              "      <td>-0.321285</td>\n",
              "      <td>-0.050938</td>\n",
              "      <td>-0.335914</td>\n",
              "      <td>-0.193496</td>\n",
              "      <td>-0.238924</td>\n",
              "      <td>-0.403374</td>\n",
              "      <td>-0.078171</td>\n",
              "      <td>-0.254132</td>\n",
              "      <td>-0.292486</td>\n",
              "      <td>0.138525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>0.257061</td>\n",
              "      <td>0.099671</td>\n",
              "      <td>0.052101</td>\n",
              "      <td>-0.119366</td>\n",
              "      <td>0.836120</td>\n",
              "      <td>-0.053816</td>\n",
              "      <td>0.548043</td>\n",
              "      <td>-0.033071</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.231611</td>\n",
              "      <td>-0.722332</td>\n",
              "      <td>0.383966</td>\n",
              "      <td>0.639221</td>\n",
              "      <td>0.380593</td>\n",
              "      <td>-0.384055</td>\n",
              "      <td>0.177628</td>\n",
              "      <td>0.410186</td>\n",
              "      <td>0.013684</td>\n",
              "      <td>0.177570</td>\n",
              "      <td>-0.260320</td>\n",
              "      <td>-0.181491</td>\n",
              "      <td>-0.297071</td>\n",
              "      <td>0.195011</td>\n",
              "      <td>0.405384</td>\n",
              "      <td>0.472922</td>\n",
              "      <td>0.265625</td>\n",
              "      <td>0.371226</td>\n",
              "      <td>0.391899</td>\n",
              "      <td>0.168496</td>\n",
              "      <td>0.538207</td>\n",
              "      <td>-0.123492</td>\n",
              "      <td>0.235418</td>\n",
              "      <td>0.217905</td>\n",
              "      <td>0.269368</td>\n",
              "      <td>0.039818</td>\n",
              "      <td>0.172831</td>\n",
              "      <td>0.168207</td>\n",
              "      <td>-0.278761</td>\n",
              "      <td>0.001874</td>\n",
              "      <td>0.168008</td>\n",
              "      <td>...</td>\n",
              "      <td>0.203467</td>\n",
              "      <td>-0.758745</td>\n",
              "      <td>0.020250</td>\n",
              "      <td>0.274074</td>\n",
              "      <td>-0.176871</td>\n",
              "      <td>-0.069272</td>\n",
              "      <td>-0.094057</td>\n",
              "      <td>0.287476</td>\n",
              "      <td>0.063714</td>\n",
              "      <td>-0.214458</td>\n",
              "      <td>0.178530</td>\n",
              "      <td>0.626880</td>\n",
              "      <td>0.427523</td>\n",
              "      <td>-0.016125</td>\n",
              "      <td>-0.413681</td>\n",
              "      <td>0.063158</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.206228</td>\n",
              "      <td>0.067717</td>\n",
              "      <td>-0.085165</td>\n",
              "      <td>-0.213418</td>\n",
              "      <td>0.171115</td>\n",
              "      <td>0.197211</td>\n",
              "      <td>0.023832</td>\n",
              "      <td>0.176680</td>\n",
              "      <td>0.163863</td>\n",
              "      <td>0.018114</td>\n",
              "      <td>0.116387</td>\n",
              "      <td>-0.019787</td>\n",
              "      <td>0.025750</td>\n",
              "      <td>-0.271084</td>\n",
              "      <td>-0.041555</td>\n",
              "      <td>0.240430</td>\n",
              "      <td>0.420488</td>\n",
              "      <td>0.322785</td>\n",
              "      <td>-0.375767</td>\n",
              "      <td>0.301812</td>\n",
              "      <td>-0.123967</td>\n",
              "      <td>0.172254</td>\n",
              "      <td>0.122741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>0.846817</td>\n",
              "      <td>0.448105</td>\n",
              "      <td>0.641457</td>\n",
              "      <td>-0.036157</td>\n",
              "      <td>0.563880</td>\n",
              "      <td>0.134013</td>\n",
              "      <td>0.627521</td>\n",
              "      <td>0.451969</td>\n",
              "      <td>0.601</td>\n",
              "      <td>0.713070</td>\n",
              "      <td>-0.155097</td>\n",
              "      <td>0.697408</td>\n",
              "      <td>0.572596</td>\n",
              "      <td>0.554910</td>\n",
              "      <td>0.588155</td>\n",
              "      <td>0.244951</td>\n",
              "      <td>0.036715</td>\n",
              "      <td>0.046524</td>\n",
              "      <td>0.620327</td>\n",
              "      <td>0.264532</td>\n",
              "      <td>0.380977</td>\n",
              "      <td>0.419008</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.311164</td>\n",
              "      <td>0.628463</td>\n",
              "      <td>0.792969</td>\n",
              "      <td>0.546477</td>\n",
              "      <td>0.539190</td>\n",
              "      <td>0.473209</td>\n",
              "      <td>0.525816</td>\n",
              "      <td>0.445146</td>\n",
              "      <td>0.607871</td>\n",
              "      <td>0.604525</td>\n",
              "      <td>0.979738</td>\n",
              "      <td>0.244596</td>\n",
              "      <td>0.613988</td>\n",
              "      <td>0.454097</td>\n",
              "      <td>-0.216814</td>\n",
              "      <td>-0.126171</td>\n",
              "      <td>0.376258</td>\n",
              "      <td>...</td>\n",
              "      <td>0.379562</td>\n",
              "      <td>-0.731996</td>\n",
              "      <td>-0.027143</td>\n",
              "      <td>-0.109630</td>\n",
              "      <td>-0.140136</td>\n",
              "      <td>0.026643</td>\n",
              "      <td>0.190998</td>\n",
              "      <td>-0.243348</td>\n",
              "      <td>0.006605</td>\n",
              "      <td>-0.373494</td>\n",
              "      <td>0.221644</td>\n",
              "      <td>0.651628</td>\n",
              "      <td>0.105254</td>\n",
              "      <td>-0.103580</td>\n",
              "      <td>-0.345277</td>\n",
              "      <td>-0.389474</td>\n",
              "      <td>-0.362319</td>\n",
              "      <td>-0.095329</td>\n",
              "      <td>-0.464567</td>\n",
              "      <td>-0.262363</td>\n",
              "      <td>-0.036461</td>\n",
              "      <td>0.216641</td>\n",
              "      <td>0.057769</td>\n",
              "      <td>-0.288847</td>\n",
              "      <td>-0.206395</td>\n",
              "      <td>-0.119003</td>\n",
              "      <td>0.079325</td>\n",
              "      <td>0.325613</td>\n",
              "      <td>-0.421613</td>\n",
              "      <td>0.037743</td>\n",
              "      <td>-0.433735</td>\n",
              "      <td>-0.332440</td>\n",
              "      <td>-0.078710</td>\n",
              "      <td>-0.108293</td>\n",
              "      <td>-0.210443</td>\n",
              "      <td>-0.526074</td>\n",
              "      <td>0.175841</td>\n",
              "      <td>0.013430</td>\n",
              "      <td>0.076879</td>\n",
              "      <td>0.296366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>0.327908</td>\n",
              "      <td>0.375618</td>\n",
              "      <td>0.226891</td>\n",
              "      <td>-0.250124</td>\n",
              "      <td>0.135786</td>\n",
              "      <td>0.310587</td>\n",
              "      <td>0.555160</td>\n",
              "      <td>0.510761</td>\n",
              "      <td>0.355</td>\n",
              "      <td>0.530699</td>\n",
              "      <td>0.029750</td>\n",
              "      <td>0.418927</td>\n",
              "      <td>-0.190446</td>\n",
              "      <td>0.345729</td>\n",
              "      <td>0.108884</td>\n",
              "      <td>0.367167</td>\n",
              "      <td>-0.367548</td>\n",
              "      <td>-0.424193</td>\n",
              "      <td>0.357477</td>\n",
              "      <td>0.064869</td>\n",
              "      <td>0.265810</td>\n",
              "      <td>0.095039</td>\n",
              "      <td>0.250567</td>\n",
              "      <td>0.533650</td>\n",
              "      <td>0.541562</td>\n",
              "      <td>0.144531</td>\n",
              "      <td>0.160450</td>\n",
              "      <td>0.422409</td>\n",
              "      <td>-0.088444</td>\n",
              "      <td>0.185461</td>\n",
              "      <td>0.074095</td>\n",
              "      <td>-0.004919</td>\n",
              "      <td>0.351697</td>\n",
              "      <td>0.573302</td>\n",
              "      <td>-0.228669</td>\n",
              "      <td>0.258911</td>\n",
              "      <td>0.173136</td>\n",
              "      <td>0.013274</td>\n",
              "      <td>0.004997</td>\n",
              "      <td>0.323944</td>\n",
              "      <td>...</td>\n",
              "      <td>0.150547</td>\n",
              "      <td>-0.908436</td>\n",
              "      <td>-0.034899</td>\n",
              "      <td>-0.063704</td>\n",
              "      <td>-0.491156</td>\n",
              "      <td>-0.083481</td>\n",
              "      <td>-0.200231</td>\n",
              "      <td>-0.011032</td>\n",
              "      <td>-0.289433</td>\n",
              "      <td>-0.368675</td>\n",
              "      <td>-0.207755</td>\n",
              "      <td>0.458976</td>\n",
              "      <td>0.219016</td>\n",
              "      <td>-0.012298</td>\n",
              "      <td>-0.263844</td>\n",
              "      <td>-0.036842</td>\n",
              "      <td>-0.284058</td>\n",
              "      <td>-0.430210</td>\n",
              "      <td>-0.533858</td>\n",
              "      <td>-0.134615</td>\n",
              "      <td>-0.114244</td>\n",
              "      <td>-0.095761</td>\n",
              "      <td>-0.147410</td>\n",
              "      <td>-0.443279</td>\n",
              "      <td>-0.309432</td>\n",
              "      <td>-0.212461</td>\n",
              "      <td>-0.374141</td>\n",
              "      <td>-0.175063</td>\n",
              "      <td>-0.339422</td>\n",
              "      <td>-0.057496</td>\n",
              "      <td>-0.538153</td>\n",
              "      <td>-0.292225</td>\n",
              "      <td>0.195699</td>\n",
              "      <td>-0.259187</td>\n",
              "      <td>-0.310127</td>\n",
              "      <td>-0.657975</td>\n",
              "      <td>-0.287662</td>\n",
              "      <td>-0.436983</td>\n",
              "      <td>-0.291908</td>\n",
              "      <td>0.088266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>0.911920</td>\n",
              "      <td>0.312191</td>\n",
              "      <td>0.545098</td>\n",
              "      <td>0.128281</td>\n",
              "      <td>0.783946</td>\n",
              "      <td>0.393598</td>\n",
              "      <td>0.978648</td>\n",
              "      <td>0.728084</td>\n",
              "      <td>0.623</td>\n",
              "      <td>0.698480</td>\n",
              "      <td>-0.067830</td>\n",
              "      <td>0.861362</td>\n",
              "      <td>0.297297</td>\n",
              "      <td>0.349216</td>\n",
              "      <td>0.680182</td>\n",
              "      <td>0.201450</td>\n",
              "      <td>0.483616</td>\n",
              "      <td>0.102354</td>\n",
              "      <td>0.587617</td>\n",
              "      <td>0.425442</td>\n",
              "      <td>0.519794</td>\n",
              "      <td>0.554094</td>\n",
              "      <td>0.770975</td>\n",
              "      <td>0.923199</td>\n",
              "      <td>0.926322</td>\n",
              "      <td>0.477539</td>\n",
              "      <td>0.660154</td>\n",
              "      <td>0.809574</td>\n",
              "      <td>0.278244</td>\n",
              "      <td>0.847997</td>\n",
              "      <td>0.347501</td>\n",
              "      <td>0.714687</td>\n",
              "      <td>0.451058</td>\n",
              "      <td>0.847437</td>\n",
              "      <td>-0.282139</td>\n",
              "      <td>0.475454</td>\n",
              "      <td>0.513247</td>\n",
              "      <td>0.321903</td>\n",
              "      <td>0.104310</td>\n",
              "      <td>0.748491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.473540</td>\n",
              "      <td>-0.856996</td>\n",
              "      <td>-0.286514</td>\n",
              "      <td>-0.425185</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.335702</td>\n",
              "      <td>0.133295</td>\n",
              "      <td>-0.051265</td>\n",
              "      <td>-0.182984</td>\n",
              "      <td>-0.508434</td>\n",
              "      <td>-0.426794</td>\n",
              "      <td>-0.342471</td>\n",
              "      <td>-0.008841</td>\n",
              "      <td>-0.420060</td>\n",
              "      <td>-0.589577</td>\n",
              "      <td>-0.115789</td>\n",
              "      <td>-0.736232</td>\n",
              "      <td>-0.761267</td>\n",
              "      <td>-0.458268</td>\n",
              "      <td>-0.583791</td>\n",
              "      <td>-0.506077</td>\n",
              "      <td>-0.314757</td>\n",
              "      <td>-0.494024</td>\n",
              "      <td>-0.469971</td>\n",
              "      <td>-0.315245</td>\n",
              "      <td>-0.234891</td>\n",
              "      <td>-0.311680</td>\n",
              "      <td>-0.297433</td>\n",
              "      <td>-0.287671</td>\n",
              "      <td>-0.175309</td>\n",
              "      <td>-0.558233</td>\n",
              "      <td>-0.569705</td>\n",
              "      <td>-0.526022</td>\n",
              "      <td>-0.222114</td>\n",
              "      <td>-0.501582</td>\n",
              "      <td>-0.618098</td>\n",
              "      <td>-0.267990</td>\n",
              "      <td>-0.235537</td>\n",
              "      <td>-0.263006</td>\n",
              "      <td>-0.403531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>0.590235</td>\n",
              "      <td>0.581549</td>\n",
              "      <td>0.349020</td>\n",
              "      <td>-0.468053</td>\n",
              "      <td>-0.174582</td>\n",
              "      <td>0.114316</td>\n",
              "      <td>0.041518</td>\n",
              "      <td>0.256693</td>\n",
              "      <td>0.429</td>\n",
              "      <td>0.238906</td>\n",
              "      <td>-0.206664</td>\n",
              "      <td>0.068113</td>\n",
              "      <td>0.108737</td>\n",
              "      <td>-0.219059</td>\n",
              "      <td>0.203645</td>\n",
              "      <td>0.095805</td>\n",
              "      <td>-0.100671</td>\n",
              "      <td>-0.361795</td>\n",
              "      <td>0.185748</td>\n",
              "      <td>-0.231676</td>\n",
              "      <td>0.105398</td>\n",
              "      <td>0.022116</td>\n",
              "      <td>0.390023</td>\n",
              "      <td>0.334917</td>\n",
              "      <td>0.384131</td>\n",
              "      <td>0.440430</td>\n",
              "      <td>0.529899</td>\n",
              "      <td>0.126775</td>\n",
              "      <td>-0.107811</td>\n",
              "      <td>0.067328</td>\n",
              "      <td>-0.200460</td>\n",
              "      <td>0.297259</td>\n",
              "      <td>0.252336</td>\n",
              "      <td>0.425507</td>\n",
              "      <td>0.054608</td>\n",
              "      <td>0.311365</td>\n",
              "      <td>0.075786</td>\n",
              "      <td>0.123894</td>\n",
              "      <td>-0.129919</td>\n",
              "      <td>0.096579</td>\n",
              "      <td>...</td>\n",
              "      <td>0.130474</td>\n",
              "      <td>-0.914095</td>\n",
              "      <td>-0.233089</td>\n",
              "      <td>-0.094815</td>\n",
              "      <td>-0.395918</td>\n",
              "      <td>-0.268206</td>\n",
              "      <td>0.219850</td>\n",
              "      <td>-0.491239</td>\n",
              "      <td>-0.082362</td>\n",
              "      <td>-0.489157</td>\n",
              "      <td>-0.373553</td>\n",
              "      <td>0.105654</td>\n",
              "      <td>0.217681</td>\n",
              "      <td>0.224378</td>\n",
              "      <td>-0.622150</td>\n",
              "      <td>-0.194737</td>\n",
              "      <td>0.182609</td>\n",
              "      <td>-0.180552</td>\n",
              "      <td>-0.165354</td>\n",
              "      <td>-0.167582</td>\n",
              "      <td>-0.238697</td>\n",
              "      <td>0.109890</td>\n",
              "      <td>-0.432271</td>\n",
              "      <td>-0.222116</td>\n",
              "      <td>-0.310724</td>\n",
              "      <td>-0.114019</td>\n",
              "      <td>-0.283573</td>\n",
              "      <td>-0.181239</td>\n",
              "      <td>-0.175038</td>\n",
              "      <td>-0.099824</td>\n",
              "      <td>-0.287149</td>\n",
              "      <td>-0.213137</td>\n",
              "      <td>-0.272258</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>-0.156646</td>\n",
              "      <td>-0.440184</td>\n",
              "      <td>-0.291113</td>\n",
              "      <td>-0.608471</td>\n",
              "      <td>0.187283</td>\n",
              "      <td>0.056698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>0.213978</td>\n",
              "      <td>-0.102965</td>\n",
              "      <td>0.065546</td>\n",
              "      <td>-0.431402</td>\n",
              "      <td>-0.127759</td>\n",
              "      <td>-0.009497</td>\n",
              "      <td>0.408066</td>\n",
              "      <td>0.095013</td>\n",
              "      <td>0.149</td>\n",
              "      <td>0.361702</td>\n",
              "      <td>-0.213011</td>\n",
              "      <td>0.128391</td>\n",
              "      <td>-0.037084</td>\n",
              "      <td>-0.013364</td>\n",
              "      <td>-0.140774</td>\n",
              "      <td>0.089591</td>\n",
              "      <td>-0.090407</td>\n",
              "      <td>-0.472359</td>\n",
              "      <td>0.214953</td>\n",
              "      <td>0.074979</td>\n",
              "      <td>0.072494</td>\n",
              "      <td>-0.286312</td>\n",
              "      <td>0.015873</td>\n",
              "      <td>0.653207</td>\n",
              "      <td>0.571788</td>\n",
              "      <td>0.107422</td>\n",
              "      <td>0.185317</td>\n",
              "      <td>0.500263</td>\n",
              "      <td>-0.222724</td>\n",
              "      <td>-0.163156</td>\n",
              "      <td>-0.145319</td>\n",
              "      <td>-0.312720</td>\n",
              "      <td>-0.027054</td>\n",
              "      <td>0.179976</td>\n",
              "      <td>-0.060296</td>\n",
              "      <td>-0.026227</td>\n",
              "      <td>-0.012939</td>\n",
              "      <td>-0.048673</td>\n",
              "      <td>-0.491568</td>\n",
              "      <td>0.108652</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012774</td>\n",
              "      <td>-0.626543</td>\n",
              "      <td>0.264972</td>\n",
              "      <td>0.231111</td>\n",
              "      <td>0.114286</td>\n",
              "      <td>0.037300</td>\n",
              "      <td>0.151760</td>\n",
              "      <td>0.543154</td>\n",
              "      <td>0.344600</td>\n",
              "      <td>0.175904</td>\n",
              "      <td>0.311921</td>\n",
              "      <td>0.283457</td>\n",
              "      <td>0.490575</td>\n",
              "      <td>0.417327</td>\n",
              "      <td>-0.615635</td>\n",
              "      <td>0.147368</td>\n",
              "      <td>0.081159</td>\n",
              "      <td>-0.142857</td>\n",
              "      <td>-0.256693</td>\n",
              "      <td>-0.006868</td>\n",
              "      <td>0.577054</td>\n",
              "      <td>0.867347</td>\n",
              "      <td>-0.047809</td>\n",
              "      <td>-0.225929</td>\n",
              "      <td>0.392765</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.307308</td>\n",
              "      <td>0.424821</td>\n",
              "      <td>0.211568</td>\n",
              "      <td>0.283951</td>\n",
              "      <td>-0.128514</td>\n",
              "      <td>-0.097855</td>\n",
              "      <td>0.541505</td>\n",
              "      <td>0.185041</td>\n",
              "      <td>-0.109177</td>\n",
              "      <td>-0.429448</td>\n",
              "      <td>0.360138</td>\n",
              "      <td>0.302686</td>\n",
              "      <td>0.231792</td>\n",
              "      <td>0.531464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>0.437051</td>\n",
              "      <td>-0.200988</td>\n",
              "      <td>-0.024090</td>\n",
              "      <td>0.149084</td>\n",
              "      <td>-0.287625</td>\n",
              "      <td>0.309884</td>\n",
              "      <td>0.093713</td>\n",
              "      <td>0.017323</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>-0.057751</td>\n",
              "      <td>-0.461325</td>\n",
              "      <td>0.146474</td>\n",
              "      <td>0.044626</td>\n",
              "      <td>0.042417</td>\n",
              "      <td>-0.179043</td>\n",
              "      <td>0.153806</td>\n",
              "      <td>-0.380971</td>\n",
              "      <td>0.264368</td>\n",
              "      <td>0.242991</td>\n",
              "      <td>-0.084246</td>\n",
              "      <td>0.021080</td>\n",
              "      <td>-0.101016</td>\n",
              "      <td>0.217687</td>\n",
              "      <td>0.092637</td>\n",
              "      <td>-0.119018</td>\n",
              "      <td>0.647461</td>\n",
              "      <td>0.714624</td>\n",
              "      <td>0.106786</td>\n",
              "      <td>0.233054</td>\n",
              "      <td>-0.444857</td>\n",
              "      <td>-0.543940</td>\n",
              "      <td>0.148278</td>\n",
              "      <td>0.385145</td>\n",
              "      <td>0.495828</td>\n",
              "      <td>-0.315131</td>\n",
              "      <td>0.098857</td>\n",
              "      <td>0.412200</td>\n",
              "      <td>0.481195</td>\n",
              "      <td>-0.652717</td>\n",
              "      <td>-0.123742</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>-0.683642</td>\n",
              "      <td>-0.184834</td>\n",
              "      <td>-0.091852</td>\n",
              "      <td>-0.115646</td>\n",
              "      <td>0.037300</td>\n",
              "      <td>0.046740</td>\n",
              "      <td>0.035691</td>\n",
              "      <td>-0.065657</td>\n",
              "      <td>-0.402410</td>\n",
              "      <td>-0.223090</td>\n",
              "      <td>-0.042071</td>\n",
              "      <td>0.297415</td>\n",
              "      <td>0.161520</td>\n",
              "      <td>-0.475570</td>\n",
              "      <td>-0.257895</td>\n",
              "      <td>-0.324638</td>\n",
              "      <td>-0.467905</td>\n",
              "      <td>-0.118110</td>\n",
              "      <td>-0.096154</td>\n",
              "      <td>-0.271755</td>\n",
              "      <td>0.268446</td>\n",
              "      <td>-0.015936</td>\n",
              "      <td>-0.243089</td>\n",
              "      <td>-0.064922</td>\n",
              "      <td>0.095327</td>\n",
              "      <td>-0.398501</td>\n",
              "      <td>-0.142251</td>\n",
              "      <td>-0.375951</td>\n",
              "      <td>-0.151323</td>\n",
              "      <td>-0.387550</td>\n",
              "      <td>-0.241287</td>\n",
              "      <td>-0.120000</td>\n",
              "      <td>-0.175935</td>\n",
              "      <td>0.033228</td>\n",
              "      <td>-0.317485</td>\n",
              "      <td>-0.020880</td>\n",
              "      <td>-0.309917</td>\n",
              "      <td>-0.393642</td>\n",
              "      <td>-0.082035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>0.509813</td>\n",
              "      <td>0.184514</td>\n",
              "      <td>0.027451</td>\n",
              "      <td>-0.636454</td>\n",
              "      <td>0.112375</td>\n",
              "      <td>-0.376011</td>\n",
              "      <td>0.297746</td>\n",
              "      <td>0.124409</td>\n",
              "      <td>0.253</td>\n",
              "      <td>-0.004255</td>\n",
              "      <td>-0.398651</td>\n",
              "      <td>-0.105485</td>\n",
              "      <td>0.078567</td>\n",
              "      <td>-0.094712</td>\n",
              "      <td>-0.292027</td>\n",
              "      <td>-0.112377</td>\n",
              "      <td>0.035136</td>\n",
              "      <td>-0.566502</td>\n",
              "      <td>0.066589</td>\n",
              "      <td>-0.433867</td>\n",
              "      <td>-0.025193</td>\n",
              "      <td>-0.156007</td>\n",
              "      <td>0.012472</td>\n",
              "      <td>0.249406</td>\n",
              "      <td>0.534635</td>\n",
              "      <td>0.102539</td>\n",
              "      <td>0.025459</td>\n",
              "      <td>0.141504</td>\n",
              "      <td>-0.034216</td>\n",
              "      <td>-0.068980</td>\n",
              "      <td>-0.318782</td>\n",
              "      <td>0.092059</td>\n",
              "      <td>0.155927</td>\n",
              "      <td>-0.033373</td>\n",
              "      <td>-0.011377</td>\n",
              "      <td>-0.067922</td>\n",
              "      <td>-0.206408</td>\n",
              "      <td>-0.719027</td>\n",
              "      <td>-0.109307</td>\n",
              "      <td>0.138833</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.221715</td>\n",
              "      <td>-0.684671</td>\n",
              "      <td>0.095218</td>\n",
              "      <td>-0.514074</td>\n",
              "      <td>-0.197279</td>\n",
              "      <td>-0.232682</td>\n",
              "      <td>0.019042</td>\n",
              "      <td>0.418559</td>\n",
              "      <td>-0.096348</td>\n",
              "      <td>-0.339759</td>\n",
              "      <td>-0.241319</td>\n",
              "      <td>0.177994</td>\n",
              "      <td>0.260717</td>\n",
              "      <td>-0.170812</td>\n",
              "      <td>-0.530945</td>\n",
              "      <td>-0.410526</td>\n",
              "      <td>-0.539130</td>\n",
              "      <td>-0.732314</td>\n",
              "      <td>-0.486614</td>\n",
              "      <td>-0.333791</td>\n",
              "      <td>-0.333982</td>\n",
              "      <td>-0.127159</td>\n",
              "      <td>-0.023904</td>\n",
              "      <td>-0.428027</td>\n",
              "      <td>-0.187339</td>\n",
              "      <td>-0.282243</td>\n",
              "      <td>-0.334791</td>\n",
              "      <td>-0.221386</td>\n",
              "      <td>-0.305936</td>\n",
              "      <td>-0.089242</td>\n",
              "      <td>-0.594378</td>\n",
              "      <td>-0.471850</td>\n",
              "      <td>-0.158710</td>\n",
              "      <td>-0.060813</td>\n",
              "      <td>-0.329114</td>\n",
              "      <td>-0.636503</td>\n",
              "      <td>-0.057808</td>\n",
              "      <td>-0.302686</td>\n",
              "      <td>-0.157803</td>\n",
              "      <td>-0.134787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>0.288655</td>\n",
              "      <td>-0.021417</td>\n",
              "      <td>0.075630</td>\n",
              "      <td>-0.421496</td>\n",
              "      <td>0.359866</td>\n",
              "      <td>-0.153711</td>\n",
              "      <td>0.459075</td>\n",
              "      <td>0.016273</td>\n",
              "      <td>0.236</td>\n",
              "      <td>0.054103</td>\n",
              "      <td>-0.313764</td>\n",
              "      <td>0.097046</td>\n",
              "      <td>-0.152734</td>\n",
              "      <td>0.126089</td>\n",
              "      <td>-0.350342</td>\n",
              "      <td>-0.186950</td>\n",
              "      <td>-0.152783</td>\n",
              "      <td>-0.365079</td>\n",
              "      <td>0.396028</td>\n",
              "      <td>0.141533</td>\n",
              "      <td>-0.374807</td>\n",
              "      <td>-0.221757</td>\n",
              "      <td>0.004535</td>\n",
              "      <td>0.267617</td>\n",
              "      <td>0.517632</td>\n",
              "      <td>0.272461</td>\n",
              "      <td>0.117821</td>\n",
              "      <td>0.223567</td>\n",
              "      <td>0.276953</td>\n",
              "      <td>-0.017761</td>\n",
              "      <td>0.244113</td>\n",
              "      <td>-0.010541</td>\n",
              "      <td>-0.090015</td>\n",
              "      <td>0.268176</td>\n",
              "      <td>-0.025028</td>\n",
              "      <td>-0.069267</td>\n",
              "      <td>0.100431</td>\n",
              "      <td>-0.118363</td>\n",
              "      <td>0.163648</td>\n",
              "      <td>0.356137</td>\n",
              "      <td>...</td>\n",
              "      <td>0.348540</td>\n",
              "      <td>-0.615741</td>\n",
              "      <td>0.208100</td>\n",
              "      <td>-0.320000</td>\n",
              "      <td>0.247619</td>\n",
              "      <td>-0.495560</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.178456</td>\n",
              "      <td>0.481352</td>\n",
              "      <td>0.166265</td>\n",
              "      <td>0.208623</td>\n",
              "      <td>0.747573</td>\n",
              "      <td>0.606339</td>\n",
              "      <td>0.672588</td>\n",
              "      <td>-0.153094</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-0.052174</td>\n",
              "      <td>-0.088227</td>\n",
              "      <td>-0.061417</td>\n",
              "      <td>0.302198</td>\n",
              "      <td>-0.378707</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>-0.007968</td>\n",
              "      <td>-0.073403</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.051713</td>\n",
              "      <td>0.132417</td>\n",
              "      <td>0.319436</td>\n",
              "      <td>0.336377</td>\n",
              "      <td>0.386949</td>\n",
              "      <td>-0.200803</td>\n",
              "      <td>0.135389</td>\n",
              "      <td>0.009892</td>\n",
              "      <td>0.339837</td>\n",
              "      <td>0.278481</td>\n",
              "      <td>-0.277607</td>\n",
              "      <td>0.242796</td>\n",
              "      <td>-0.033058</td>\n",
              "      <td>0.056069</td>\n",
              "      <td>0.516096</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>218 rows × 524 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2    ...       521       522       523\n",
              "495  0.564385  0.016474  0.484594  ... -0.254132 -0.292486  0.138525\n",
              "617  0.257061  0.099671  0.052101  ... -0.123967  0.172254  0.122741\n",
              "618  0.846817  0.448105  0.641457  ...  0.013430  0.076879  0.296366\n",
              "80   0.327908  0.375618  0.226891  ... -0.436983 -0.291908  0.088266\n",
              "76   0.911920  0.312191  0.545098  ... -0.235537 -0.263006 -0.403531\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "193  0.590235  0.581549  0.349020  ... -0.608471  0.187283  0.056698\n",
              "541  0.213978 -0.102965  0.065546  ...  0.302686  0.231792  0.531464\n",
              "222  0.437051 -0.200988 -0.024090  ... -0.309917 -0.393642 -0.082035\n",
              "291  0.509813  0.184514  0.027451  ... -0.302686 -0.157803 -0.134787\n",
              "249  0.288655 -0.021417  0.075630  ... -0.033058  0.056069  0.516096\n",
              "\n",
              "[218 rows x 524 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0xNNbvyS_Wu"
      },
      "source": [
        "# PCA\r\n",
        "let:\r\n",
        "1 be functional data,\r\n",
        "2 be structural data (std scaled),\r\n",
        "and 3 be structural data (minmax scaled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCfPGN0C7v2j"
      },
      "source": [
        "# from sklearn.decomposition import PCA\r\n",
        "# pca1 = pca2 = pca3 = pca4 = pca5 = PCA(n_components= 0.95)\r\n",
        "\r\n",
        "\r\n",
        "# pca1.fit(x1_train)\r\n",
        "# x1_train_pca = pca1.transform(x1_train)\r\n",
        "# x1_test_pca = pca1.transform(x1_test)\r\n",
        "# print(x1_train_pca.shape, x1_test_pca.shape)\r\n",
        "\r\n",
        "# pca2.fit(x2_train)\r\n",
        "# x2_train_pca = pca1.transform(x2_train)\r\n",
        "# x2_test_pca = pca1.transform(x2_test)\r\n",
        "# print(x2_train_pca.shape, x2_test_pca.shape)\r\n",
        "\r\n",
        "# pca3.fit(x3_train)\r\n",
        "# x3_train_pca = pca3.transform(x3_train)\r\n",
        "# x3_test_pca = pca3.transform(x3_test)\r\n",
        "# print(x3_train_pca.shape, x3_test_pca.shape)\r\n",
        "\r\n",
        "# pca4.fit(x4_train)\r\n",
        "# x4_train_pca = pca4.transform(x4_train)\r\n",
        "# x4_test_pca = pca4.transform(x4_test)\r\n",
        "# print(x4_train_pca.shape, x4_test_pca.shape)\r\n",
        "\r\n",
        "# pca5.fit(x5_train)\r\n",
        "# x5_train_pca = pca5.transform(x5_train)\r\n",
        "# x5_test_pca = pca5.transform(x5_test)\r\n",
        "# print(x5_train_pca.shape, x5_test_pca.shape)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-QoKm_bn19w"
      },
      "source": [
        "#import matplotlib.pyplot as plt\r\n",
        "# pca = PCA(n_components= 700)\r\n",
        "# pca.fit(func_aal.iloc[:,:-2])\r\n",
        "# reduced1 = pca.transform(func_aal.iloc[:,:-2])\r\n",
        "# cum_exp_var = []\r\n",
        "# var_exp = 0\r\n",
        "# for i in pca.explained_variance_ratio_:\r\n",
        "#     var_exp += i\r\n",
        "#     cum_exp_var.append(var_exp)\r\n",
        "\r\n",
        "# # Plot cumulative explained variance for all PCs\r\n",
        "\r\n",
        "# fig, ax = plt.subplots(figsize=(8,6))\r\n",
        "# ax.bar(range(1,701), cum_exp_var)\r\n",
        "# ax.set_xlabel('# Principal Components')\r\n",
        "# ax.set_ylabel('% Cumulative Variance Explained')"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImGd_je9nbgO"
      },
      "source": [
        "# Grid Search for hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0I4u0x_WMh-"
      },
      "source": [
        "**1) Using functional data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjGDSCqLVRie"
      },
      "source": [
        "\r\n",
        "#Create classifier object\r\n",
        "from sklearn.svm import SVC\r\n",
        "classifier_svm_kernel = SVC(kernel='rbf')\r\n",
        "classifier_svm_kernel.fit(x1_train,y1_train)\r\n",
        "\r\n",
        "#Predict the result for test values\r\n",
        "y_pred = classifier_svm_kernel.predict(x1_test)\r\n",
        "\r\n",
        "#Apply k-fold validation here\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "accuracies = cross_val_score(estimator=classifier_svm_kernel,X=x1_train,y=y1_train,cv=10)\r\n",
        "print (accuracies)\r\n",
        "\r\n",
        "#Applying grid search for optimal parameters and model after k-fold validation\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "#parameters = [{'C':[0.0001,0.001,0.01,0.1,1,10], 'kernel':['linear'], 'gamma': [1e-100,1e-20,1e-09,0.000001, 0.00001]}]\r\n",
        "parameters = [ {'C': [0.001, 0.1 , 1, 10, 100, 1000], 'kernel': ['linear','rbf'], 'gamma': [ 0.1 , 0.01, 0.001, 1e-20,1e-09, 0.00001]} ]\r\n",
        "grid_search = GridSearchCV(estimator=classifier_svm_kernel, param_grid=parameters, scoring ='accuracy',cv=10,n_jobs=-1)\r\n",
        "grid_search_ = grid_search.fit(x1_train,y1_train)\r\n",
        "\r\n",
        "best_accuracy = grid_search_.best_score_\r\n",
        "print(\"acc:\" , best_accuracy)\r\n",
        "opt_param = grid_search_.best_params_\r\n",
        "print(\"opt param:\", opt_param)\r\n",
        "\r\n",
        "# [0.58823529 0.62745098 0.74509804 0.62745098 0.66666667 0.58823529\r\n",
        "#  0.66       0.6        0.58       0.62      ]\r\n",
        "# acc: 0.6363529411764705\r\n",
        "# opt param: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo8TiBuBWGW8"
      },
      "source": [
        "**2) Using structural data (std scaled)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FfSLkdd8ISQ"
      },
      "source": [
        "#Create classifier object\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "classifier_svm_kernel2 = SVC(kernel='rbf')\r\n",
        "classifier_svm_kernel2.fit(x2_train,y2_train)\r\n",
        "\r\n",
        "#Predict the result for test values\r\n",
        "y_pred = classifier_svm_kernel2.predict(x2_test)\r\n",
        "\r\n",
        "#Apply k-fold validation here\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "accuracies = cross_val_score(estimator=classifier_svm_kernel2,X=x2_train,y=y2_train,cv=10)\r\n",
        "print (accuracies)\r\n",
        "\r\n",
        "#Applying grid search for optimal parameters and model after k-fold validation\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "parameters = [ {'C': [0.001, 0.1 , 1, 10, 100, 1000], 'kernel': ['linear','rbf'], 'gamma': [ 0.1 , 0.01, 0.001, 1e-20,1e-09, 0.00001]} ]\r\n",
        "\r\n",
        "\r\n",
        "grid_search = GridSearchCV(estimator=classifier_svm_kernel2, param_grid=parameters, scoring ='accuracy',cv=10,n_jobs=-1)\r\n",
        "grid_search = grid_search.fit(x2_train,y2_train)\r\n",
        "\r\n",
        "best_accuracy = grid_search.best_score_\r\n",
        "print(\"acc:\" , best_accuracy)\r\n",
        "opt_param = grid_search.best_params_\r\n",
        "print(\"opt param:\", opt_param)\r\n",
        "\r\n",
        "# [0.64705882 0.54901961 0.68627451 0.56862745 0.47058824 0.58823529\r\n",
        "#  0.46       0.52       0.66       0.6       ]\r\n",
        "# acc: 0.5690196078431373\r\n",
        "# opt param: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUOY89ifWEwD"
      },
      "source": [
        "**3) Using structural data (minmax scaled)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v18t4raF8dSs"
      },
      "source": [
        "#Create classifier object\r\n",
        "from sklearn.svm import SVC \r\n",
        "\r\n",
        "classifier_svm_kernel3 = SVC(kernel='rbf')\r\n",
        "classifier_svm_kernel3.fit(x3_train,y3_train)\r\n",
        "\r\n",
        "#Predict the result for test values\r\n",
        "y_pred = classifier_svm_kernel3.predict(x3_test)\r\n",
        "\r\n",
        "#Apply k-fold validation here\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "accuracies = cross_val_score(estimator=classifier_svm_kernel3,X=x3_train,y=y3_train,cv=10)\r\n",
        "print (accuracies)\r\n",
        "\r\n",
        "#Applying grid search for optimal parameters and model after k-fold validation\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "parameters = [ {'C': [0.001, 0.1 , 1, 10, 100, 1000], 'kernel': ['linear','rbf'], 'gamma': [ 0.1 , 0.01, 0.001, 1e-20,1e-09, 0.00001]} ]\r\n",
        "\r\n",
        "grid_search = GridSearchCV(estimator=classifier_svm_kernel3, param_grid=parameters, scoring ='accuracy',cv=10,n_jobs=-1)\r\n",
        "grid_search = grid_search.fit(x3_train,y3_train)\r\n",
        "\r\n",
        "best_accuracy = grid_search.best_score_\r\n",
        "print(\"acc:\" , best_accuracy)\r\n",
        "opt_param = grid_search.best_params_\r\n",
        "print(\"opt param:\", opt_param)\r\n",
        "\r\n",
        "# [0.60784314 0.54901961 0.68627451 0.58823529 0.47058824 0.56862745\r\n",
        "#  0.5        0.52       0.62       0.56      ]\r\n",
        "# acc: 0.5793333333333334\r\n",
        "# opt param: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kKNAVT3V9bx"
      },
      "source": [
        "**4) Using combined data (functional and structural (minmax-scaled))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JSe8FoZJ-LB"
      },
      "source": [
        "#Create classifier object\r\n",
        "from sklearn.svm import SVC \r\n",
        "\r\n",
        "classifier_svm_kernel4 = SVC(kernel='rbf')\r\n",
        "classifier_svm_kernel4.fit(x4_train,y4_train)\r\n",
        "\r\n",
        "#Predict the result for test values\r\n",
        "y_pred = classifier_svm_kernel4.predict(x4_test)\r\n",
        "\r\n",
        "#Apply k-fold validation here\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "accuracies = cross_val_score(estimator=classifier_svm_kernel4,X=x4_train,y=y4_train,cv=10)\r\n",
        "print (accuracies)\r\n",
        "\r\n",
        "#Applying grid search for optimal parameters and model after k-fold validation\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "parameters = [ {'C': [0.001, 0.1 , 1, 10, 100, 1000], 'kernel': ['linear','rbf'], 'gamma': [ 0.1 , 0.01, 0.001, 1e-20,1e-09, 0.00001]} ]\r\n",
        "\r\n",
        "grid_search = GridSearchCV(estimator=classifier_svm_kernel4, param_grid=parameters, scoring ='accuracy',cv=10,n_jobs=-1)\r\n",
        "grid_search = grid_search.fit(x4_train,y4_train)\r\n",
        "\r\n",
        "best_accuracy = grid_search.best_score_\r\n",
        "print(\"acc:\" , best_accuracy)\r\n",
        "opt_param = grid_search.best_params_\r\n",
        "print(\"opt param:\", opt_param)\r\n",
        "\r\n",
        "\r\n",
        "# [0.64705882 0.66666667 0.70588235 0.52941176 0.58823529 0.62745098\r\n",
        "#  0.64       0.6        0.56       0.66      ]\r\n",
        "# acc: 0.6402745098039215\r\n",
        "# opt param: {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ-F09GHXVfB"
      },
      "source": [
        "**5) Using combined data (functional and structural (std-scaled))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTvJRr0gXDyO"
      },
      "source": [
        "#Create classifier object\r\n",
        "from sklearn.svm import SVC \r\n",
        "\r\n",
        "classifier_svm_kernel5 = SVC(kernel='rbf')\r\n",
        "classifier_svm_kernel5.fit(x5_train,y5_train)\r\n",
        "\r\n",
        "#Predict the result for test values\r\n",
        "y_pred = classifier_svm_kernel5.predict(x5_test)\r\n",
        "\r\n",
        "#Apply k-fold validation here\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "accuracies = cross_val_score(estimator=classifier_svm_kernel5,X=x5_train,y=y5_train,cv=10)\r\n",
        "print(accuracies)\r\n",
        "\r\n",
        "#Applying grid search for optimal parameters and model after k-fold validation\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "parameters = [ {'C': [0.001, 0.1 , 1, 10, 100, 1000], 'kernel': ['linear','rbf'], 'gamma': [ 0.1 , 0.01, 0.001, 1e-20,1e-09, 0.00001]} ]\r\n",
        "\r\n",
        "grid_search = GridSearchCV(estimator=classifier_svm_kernel5, param_grid=parameters, scoring ='accuracy',cv=10,n_jobs=-1)\r\n",
        "grid_search = grid_search.fit(x5_train,y5_train)\r\n",
        "\r\n",
        "best_accuracy = grid_search.best_score_\r\n",
        "print(\"acc:\" , best_accuracy)\r\n",
        "opt_param = grid_search.best_params_\r\n",
        "print(\"opt param:\", opt_param)\r\n",
        "\r\n",
        "# [0.68627451 0.62745098 0.68627451 0.54901961 0.50980392 0.62745098\r\n",
        "#  0.6        0.5        0.64       0.6       ]\r\n",
        "# acc: 0.6147058823529412\r\n",
        "# opt param: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHKSYlFsv0W7"
      },
      "source": [
        "# SVM classifier\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwlPkzcbYDrp"
      },
      "source": [
        "Here we use the optimal parameters retrieved from the grid search!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqxUiuNVf67R"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn import svm\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.model_selection import cross_val_predict"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf05yppkxbR0"
      },
      "source": [
        "**1) Using functional data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4p7n0c5yVhE",
        "outputId": "4924594c-d47b-4de9-bf07-5aa5470a2bcf"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "clf1 = svm.SVC(C = 10, gamma= 0.001, kernel = 'rbf')\r\n",
        "\r\n",
        "y1_pred = cross_val_predict(clf1, x1_test, y1_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y1_test, y1_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y1_test, y1_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y1_test, y1_pred))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6513761467889908\n",
            "Precision: 0.632183908045977\n",
            "Recall: 0.5555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRKK_g65U5tZ",
        "outputId": "1e064e80-35e0-4621-989e-a45e4a577d51"
      },
      "source": [
        "#Compute confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y1_test,y1_pred)\r\n",
        "cm"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[55, 44],\n",
              "       [32, 87]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAVOuOcYfvld"
      },
      "source": [
        "**2) Using structural data (std scaled)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9ZYaTU3x_if",
        "outputId": "f5e14cf5-3728-45a7-d960-6619880f21e8"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "clf2 = svm.SVC(C = 1, gamma= 0.001, kernel = 'rbf')\r\n",
        "\r\n",
        "y2_pred = cross_val_predict(clf2, x2_test, y2_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y2_test, y2_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y2_test, y2_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y2_test, y2_pred))\r\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5275229357798165\n",
            "Precision: 0.46296296296296297\n",
            "Recall: 0.25252525252525254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-XrquRIyune",
        "outputId": "21aa3602-0062-4804-b062-8bc5dc8daeb9"
      },
      "source": [
        "#Compute confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y2_test,y2_pred)\r\n",
        "cm"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[25, 74],\n",
              "       [29, 90]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp02831_hoEX"
      },
      "source": [
        "**3) Using structural data (minmax scaled)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpi4lNkVh1VS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3d14cb-7dd9-4c4c-f697-49be58713a69"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "clf3 = svm.SVC(C = 10, gamma= 0.1, kernel = 'rbf')\r\n",
        "\r\n",
        "y3_pred = cross_val_predict(clf3, x3_test, y3_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y3_test, y3_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y3_test, y3_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y3_test, y3_pred))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.518348623853211\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE0ylIrrzZM3",
        "outputId": "03238882-1412-4f46-c661-4005df71bd20"
      },
      "source": [
        "#Compute confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y3_test,y3_pred)\r\n",
        "cm"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,  99],\n",
              "       [  6, 113]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGW0MDQkJhFE"
      },
      "source": [
        "**4) Using combined data (functional + structural (minmax-scaled))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2SFj3vIztiH",
        "outputId": "e824f4a8-65e5-41a7-d9f2-74703e8d7754"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "clf4 = svm.SVC(C = 1000, gamma= 1e-05, kernel = 'rbf')\r\n",
        "\r\n",
        "y4_pred = cross_val_predict(clf4, x4_test, y4_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y4_test, y4_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y4_test, y4_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y4_test, y4_pred))\r\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6605504587155964\n",
            "Precision: 0.631578947368421\n",
            "Recall: 0.6060606060606061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjXIWNUDztiL",
        "outputId": "afa54367-c65d-4447-f4e5-aeedcb97f102"
      },
      "source": [
        "#Compute confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y4_test,y4_pred)\r\n",
        "cm"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[60, 39],\n",
              "       [35, 84]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTPa6U2I0yxX"
      },
      "source": [
        "**5) Using combined data (functional + structural (std-scaled))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXWj9I8c0xbP",
        "outputId": "26413899-d79b-4a52-8ed7-f1aace61b3c3"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "clf5 = svm.SVC(C = 10, gamma= 0.001, kernel = 'rbf')\r\n",
        "# opt param: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\r\n",
        "\r\n",
        "y5_pred = cross_val_predict(clf5, x5_test, y5_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y5_test, y5_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y5_test, y5_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y5_test, y5_pred))\r\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5779816513761468\n",
            "Precision: 0.5393258426966292\n",
            "Recall: 0.48484848484848486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIUZ4D9e0xbS",
        "outputId": "7a5eeb4c-d969-4e34-baae-c2d5396c6e3c"
      },
      "source": [
        "#Compute confusion matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y5_test,y5_pred)\r\n",
        "cm"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[48, 51],\n",
              "       [41, 78]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQZqeQETROip"
      },
      "source": [
        "#Random Forest Grid Search "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk99GjsIRRtq"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "clf = RandomForestClassifier(random_state = 30)\r\n",
        "n_estimators = [10, 20, 200, 400]\r\n",
        "max_depth = [5, 10, 100, None]\r\n",
        "min_samples_split = [2, 10]\r\n",
        "min_samples_leaf = [1, 5]\r\n",
        "criterion= ['gini', 'entropy']\r\n",
        "\r\n",
        "\r\n",
        "parameters = dict(n_estimators = n_estimators, max_depth = max_depth,  \r\n",
        "              min_samples_split = min_samples_split, \r\n",
        "             min_samples_leaf = min_samples_leaf, criterion = criterion)\r\n",
        "grid_search = GridSearchCV(clf, parameters, cv = 10, n_jobs = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsaHHouMok2Y"
      },
      "source": [
        "grid_search = grid_search.fit(x1_train, y1_train)\r\n",
        "print (\"best params: \", grid_search.best_params_)\r\n",
        "print ('best accuracy', grid_search.best_score_)\r\n",
        "\r\n",
        "# best params:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\r\n",
        "# best accuracy 0.6225098039215686"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU4kVGipVj9X"
      },
      "source": [
        "grid_search = grid_search.fit(x2_train, y2_train)\r\n",
        "print (\"best params: \", grid_search.best_params_)\r\n",
        "print ('best accuracy', grid_search.best_score_)\r\n",
        "\r\n",
        "# best params:  {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 200}\r\n",
        "# best accuracy 0.5809803921568627"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW1ICt_tVmFj"
      },
      "source": [
        "grid_search = grid_search.fit(x3_train, y3_train)\r\n",
        "print (\"best params: \", grid_search.best_params_)\r\n",
        "print ('best accuracy', grid_search.best_score_)\r\n",
        "\r\n",
        "# best params:  {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 200}\r\n",
        "# best accuracy 0.5809803921568627"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VDJOGjmVpWZ"
      },
      "source": [
        "grid_search = grid_search.fit(x4_train, y4_train)\r\n",
        "print (\"best params: \", grid_search.best_params_)\r\n",
        "print ('best accuracy', grid_search.best_score_)\r\n",
        "\r\n",
        "# best params:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\r\n",
        "# best accuracy 0.6245490196078431"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQn3JMABVsRC"
      },
      "source": [
        "grid_search = grid_search.fit(x5_train, y5_train)\r\n",
        "print (\"best params: \", grid_search.best_params_)\r\n",
        "print ('best accuracy', grid_search.best_score_)\r\n",
        "\r\n",
        "# best params:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\r\n",
        "# best accuracy 0.6245490196078431"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5eUcKwgoLco"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKF1LWeu6B8_"
      },
      "source": [
        "Here we use the optimal parameters retrieved from the grid search!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eimMHccixIbM"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.model_selection import cross_val_predict\r\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP_UDSgr6B9Y"
      },
      "source": [
        "**1) Using functional data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_j7QWIbw5Wb",
        "outputId": "5f39caed-7494-4a79-e660-367acceceb78"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "\r\n",
        "clf1 = RandomForestClassifier(random_state = 1, criterion= 'gini', max_depth=10, n_estimators=200, min_samples_leaf=1, min_samples_split=10)\r\n",
        "# best params:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\r\n",
        "y1_pred = cross_val_predict(clf1, x1_test, y1_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y1_test, y1_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y1_test, y1_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y1_test, y1_pred))\r\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6009174311926605\n",
            "Precision: 0.62\n",
            "Recall: 0.31313131313131315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JjaRnk46B90"
      },
      "source": [
        "**2) Using structural data (std scaled)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ViJDDewxKOD",
        "outputId": "950ade0b-7c4b-4132-e9ed-c52dc29ca54c"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "clf2 = RandomForestClassifier(random_state = 1, criterion= 'entropy', max_depth=5, n_estimators=200, min_samples_leaf=5, min_samples_split=2)\r\n",
        "#best params:  {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 200}\r\n",
        "\r\n",
        "y2_pred = cross_val_predict(clf2, x2_test, y2_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y2_test, y2_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y2_test, y2_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y2_test, y2_pred))\r\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5229357798165137\n",
            "Precision: 0.4626865671641791\n",
            "Recall: 0.31313131313131315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfXtU3oW6B94"
      },
      "source": [
        "**3) Using structural data (minmax scaled)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bv1PzPU6B95",
        "outputId": "001b845d-8bf4-4074-999f-1d67b4c5908c"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "clf3 = RandomForestClassifier(random_state = 1, criterion= 'gini', max_depth=10, n_estimators=200, min_samples_leaf=1, min_samples_split=2)\r\n",
        "# best params:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\r\n",
        "\r\n",
        "y3_pred = cross_val_predict(clf3, x3_test, y3_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y3_test, y3_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y3_test, y3_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y3_test, y3_pred))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5091743119266054\n",
            "Precision: 0.4473684210526316\n",
            "Recall: 0.3434343434343434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J5xRpqu6B-A"
      },
      "source": [
        "**4) Using combined data (functional + structural (minmax-scaled))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEcmt-Ty6B-B",
        "outputId": "04ac2a1b-0fc3-4faf-fcc3-5b65fad9dcd2"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "clf4 =  RandomForestClassifier(random_state = 1, criterion= 'gini', max_depth=10, n_estimators=200, min_samples_leaf=1, min_samples_split=2)\r\n",
        "#best params:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\r\n",
        "\r\n",
        "y4_pred = cross_val_predict(clf4, x4_test, y4_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y4_test, y4_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y4_test, y4_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y4_test, y4_pred))\r\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5871559633027523\n",
            "Precision: 0.5882352941176471\n",
            "Recall: 0.30303030303030304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxq_VO576B-D"
      },
      "source": [
        "**5) Using combined data (functional + structural (std-scaled))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92Elkua96B-E",
        "outputId": "54e4a424-8729-4cde-ec47-9c0a785d4ae1"
      },
      "source": [
        "# using the optimal parameters extracted from the grid search\r\n",
        "clf5 =  RandomForestClassifier(random_state = 1, criterion= 'gini', max_depth=10, n_estimators=200, min_samples_leaf=1, min_samples_split=2)\r\n",
        "#best params:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\r\n",
        "\r\n",
        "y5_pred = cross_val_predict(clf5, x5_test, y5_test, cv=10)\r\n",
        "\r\n",
        "# Model Accuracy: how often is the classifier correct?\r\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y5_test, y5_pred))\r\n",
        "\r\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\r\n",
        "print(\"Precision:\",metrics.precision_score(y5_test, y5_pred))\r\n",
        "\r\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\r\n",
        "print(\"Recall:\",metrics.recall_score(y5_test, y5_pred))\r\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5871559633027523\n",
            "Precision: 0.5882352941176471\n",
            "Recall: 0.30303030303030304\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}